{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml_classifiers.ipynb","provenance":[],"authorship_tag":"ABX9TyMQa4qntRU3/UpjxewyF+P4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PmSt6eb3biG","executionInfo":{"status":"ok","timestamp":1642236180917,"user_tz":-480,"elapsed":18452,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"8941754a-460b-4654-91d1-7cd8ecc5aedf"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"azt_QHlp3ASC","executionInfo":{"status":"ok","timestamp":1642236185184,"user_tz":-480,"elapsed":1418,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}}},"outputs":[],"source":["import sklearn\n","import nltk\n","import re \n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_extraction.text import TfidfVectorizer #as vectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import chi2\n","from sklearn.metrics import precision_score, recall_score,f1_score\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","source":["training = pd.read_csv('/content/gdrive/My Drive/NMSM/day2/train.csv', encoding=\"utf-8\")\n","testing  = pd.read_csv('/content/gdrive/My Drive/NMSM/day2/test.csv', encoding=\"utf-8\")\n","print (training.head(5))\n","print (testing.head(5))\n","print (testing.tail(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsS50Xwv3eVy","executionInfo":{"status":"ok","timestamp":1642236190364,"user_tz":-480,"elapsed":3017,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"9640eb76-ff40-4baa-f0a4-2068f38dc2cc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  restaurant_id  ... Sentiment\n","0          tr70  ...  positive\n","1          tr70  ...  positive\n","2          tr70  ...  positive\n","3          tr70  ...  positive\n","4          tr70  ...  positive\n","\n","[5 rows x 6 columns]\n","  restaurant_id  ... Sentiment\n","0         ts106  ...  negative\n","1         ts106  ...  negative\n","2         ts106  ...  negative\n","3         ts106  ...  negative\n","4         ts106  ...  negative\n","\n","[5 rows x 6 columns]\n","     restaurant_id  ... Sentiment\n","3792          ts56  ...  negative\n","3793          ts56  ...  positive\n","3794          ts56  ...  positive\n","3795          ts56  ...  negative\n","3796          ts56  ...  positive\n","\n","[5 rows x 6 columns]\n"]}]},{"cell_type":"code","source":["#Label conversion: Positive to 1,Negative to -1 \n","train_pos = training[(training.Sentiment == 'positive')]\n","train_neg = training[(training.Sentiment == 'negative')]\n","print (train_pos.head(3))\n","print (train_pos.head(3))\n","\n","train_pos_list = []\n","for i,t in train_pos.iterrows():\n","    train_pos_list.append([t.text.lower(), 1])\n","\n","train_neg_list = []\n","for i,t in train_neg.iterrows():\n","    train_neg_list.append([t.text.lower(), -1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzfCDnZq56hq","executionInfo":{"status":"ok","timestamp":1642236208765,"user_tz":-480,"elapsed":1749,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"eebfb0ff-88a9-41d4-9419-d216a3a079ea"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["  restaurant_id  ... Sentiment\n","0          tr70  ...  positive\n","1          tr70  ...  positive\n","2          tr70  ...  positive\n","\n","[3 rows x 6 columns]\n","  restaurant_id  ... Sentiment\n","0          tr70  ...  positive\n","1          tr70  ...  positive\n","2          tr70  ...  positive\n","\n","[3 rows x 6 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import pickle as pk\n","#Same for test dataset   \n","test_pos = testing[(testing.Sentiment == 'positive')]\n","test_neg = testing[(testing.Sentiment == 'negative')]\n","\n","test_pos_list = []\n","for i,t in test_pos.iterrows():\n","    test_pos_list.append([t.text.lower(), 1])\n","\n","test_neg_list = []\n","for i,t in test_neg.iterrows():\n","    test_neg_list.append([t.text.lower(), -1])\n","\n","#build the two dataset\n","trainset = train_pos_list + train_neg_list\n","testset = test_pos_list + test_neg_list\n","\n","pk.dump(trainset, open('/content/gdrive/My Drive/NMSM/day2/trainset.pk', \"wb\"))\n","pk.dump(testset , open('/content/gdrive/My Drive/NMSM/day2/testset.pk', \"wb\"))\n"],"metadata":{"id":"DQMXHGgK5-8M","executionInfo":{"status":"ok","timestamp":1642237870028,"user_tz":-480,"elapsed":518,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["##########################################################3\n","###Preprocessing \n","# seperate the text with labels\n","\n","X_train = [t[0] for t in trainset]\n","X_test = [t[0] for t in testset]\n","\n","Y_train = [t[1] for t in trainset]\n","Y_test = [t[1] for t in testset]\n","\n","#Vectorizer the sentences using Tfidf vale\n","#Make sure test data should be transformed using vectorizer learned from trainning data \n","vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n","train_vectors = vectorizer.fit_transform(X_train)\n","test_vectors = vectorizer.transform(X_test)\n","\n","# same feature set\n","train_vectors.shape\n","test_vectors.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2UI021V6bti","executionInfo":{"status":"ok","timestamp":1642236354335,"user_tz":-480,"elapsed":7763,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"5f3884e1-d166-464f-b074-0578f782240b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3797, 549262)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#########################################################\n","#Apply NB model\n","clf_NB = MultinomialNB().fit(train_vectors, Y_train)\n","predNB = clf_NB.predict(test_vectors)\n","pred = list(predNB)\n","Y_test\n","\n","'''\n","errors=[]\n","for a,b, index in pred,Y_test:\n","    if a==b:\n","        continue\n","    else:\n","        errors.append(test_set[index])\n","print (errors)    \n","'''\n","\n","print(metrics.confusion_matrix(Y_test, pred))\n","print(metrics.classification_report(Y_test, pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q889p53T6jPr","executionInfo":{"status":"ok","timestamp":1642236370067,"user_tz":-480,"elapsed":452,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"f028dafe-7936-4c5d-d768-a9eec07c2b43"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1758   39]\n"," [1237  763]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.59      0.98      0.73      1797\n","           1       0.95      0.38      0.54      2000\n","\n","    accuracy                           0.66      3797\n","   macro avg       0.77      0.68      0.64      3797\n","weighted avg       0.78      0.66      0.63      3797\n","\n"]}]},{"cell_type":"code","source":["# MaxEnt = LogisticRegression\n","clf_ME = LogisticRegression(random_state=0, solver='lbfgs').fit(train_vectors, Y_train)\n","predME = clf_ME.predict(test_vectors)\n","pred = list(predME)\n","print(metrics.confusion_matrix(Y_test, pred))\n","print(metrics.classification_report(Y_test, pred))\n","\n","#####KNN Classifier\n","def train_knn(X, y, k, weight):\n","    \"\"\"\n","    Create and train the k-nearest neighbor.\n","    \"\"\"\n","    knn = KNeighborsClassifier(n_neighbors = k, weights = weight, metric = 'cosine', algorithm = 'brute')\n","    knn.fit(X, y)\n","    return knn\n","\n","\n","kn = train_knn(train_vectors, Y_train, 3, 'distance')# distance weights - by inverse of distance\n","predKN = kn.predict(test_vectors)\n","pred = list(predKN)\n","print(metrics.confusion_matrix(Y_test, pred))\n","print(metrics.classification_report(Y_test, pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xt0n9yU6mZ9","executionInfo":{"status":"ok","timestamp":1642236399596,"user_tz":-480,"elapsed":16017,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"a7bfc63a-b0f9-411e-aa64-eff2f69fcbd9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1589  208]\n"," [ 350 1650]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.82      0.88      0.85      1797\n","           1       0.89      0.82      0.86      2000\n","\n","    accuracy                           0.85      3797\n","   macro avg       0.85      0.85      0.85      3797\n","weighted avg       0.86      0.85      0.85      3797\n","\n","[[1377  420]\n"," [ 616 1384]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.69      0.77      0.73      1797\n","           1       0.77      0.69      0.73      2000\n","\n","    accuracy                           0.73      3797\n","   macro avg       0.73      0.73      0.73      3797\n","weighted avg       0.73      0.73      0.73      3797\n","\n"]}]},{"cell_type":"code","source":["#Apply SVM model\n","\n","from sklearn import svm\n","from sklearn.svm import LinearSVC\n","\n","model_svm = LinearSVC(C=100)\n","clr_svm = model_svm.fit(train_vectors, Y_train)\n","\n","\n","predicted = clr_svm.predict(test_vectors)\n"," \n","print(metrics.confusion_matrix(Y_test, predicted))\n","print(np.mean(predicted == Y_test) )\n","print(metrics.classification_report(Y_test, predicted))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIqDy3Hj6uou","executionInfo":{"status":"ok","timestamp":1642236451962,"user_tz":-480,"elapsed":13618,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"ce809272-b8eb-474a-e627-4faad50f3793"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1513  284]\n"," [ 277 1723]]\n","0.8522517777192521\n","              precision    recall  f1-score   support\n","\n","          -1       0.85      0.84      0.84      1797\n","           1       0.86      0.86      0.86      2000\n","\n","    accuracy                           0.85      3797\n","   macro avg       0.85      0.85      0.85      3797\n","weighted avg       0.85      0.85      0.85      3797\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","source":["#ADD Features - Negation\n","import re \n","def nega_tag(text):\n","    transformed = re.sub(r\"\\b(?:never|nothing|nowhere|noone|none|not|haven't|hasn't|hasnt|hadn't|hadnt|can't|cant|couldn't|couldnt|shouldn't|shouldnt|won't|wont|wouldn't|wouldnt|don't|dont|doesn't|doesnt|didn't|didnt|isnt|isn't|aren't|arent|aint|ain't|hardly|seldom)\\b[\\w\\s]+[^\\w\\s]\", lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1NEG_\\2', match.group(0)), text, flags=re.IGNORECASE)\n","    return(transformed)\n","\n","text = \"I don't like that place , you keep calling awesome.\"\n","print (nega_tag(text))\n","\n","# Create a training list which will now contain reviews with Negatively tagged words and their labels\n","train_set_nega = []\n","\n","# Append elements to the list\n","for doc in trainset:\n","    trans = nega_tag(doc[0])\n","    lab = doc[1]\n","    train_set_nega.append([trans, lab])\n","\n","print(train_set_nega[18])\n","\n","# Create a testing list which will now contain reviews with Negatively tagged words and their labels\n","test_set_nega = []\n","\n","# Append elements to the list\n","for doc in testset:\n","    trans = nega_tag(doc[0])\n","    lab = doc[1]\n","    test_set_nega.append([trans, lab])\n","\n","\n","#Redo - Preprocessing \n","# seperate the text with labels\n","\n","\n","X_nega_train = [t[0] for t in train_set_nega]\n","X_nega_test = [t[0] for t in test_set_nega]\n","\n","Y_nega_train = [t[1] for t in train_set_nega]\n","Y_nega_test = [t[1] for t in test_set_nega]\n","\n","#Vectorizer the sentences using Tfidf vale\n","#Make sure test data should be transformed using vectorizer learned from trainning data \n","vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=1)\n","train_nega_vectors = vectorizer.fit_transform(X_nega_train)\n","test_nega_vectors = vectorizer.transform(X_nega_test)\n","\n","# bigger feature set\n","train_vectors.shape\n","test_vectors.shape\n","\n","train_nega_vectors.shape\n","test_nega_vectors.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjtuHp2E67As","executionInfo":{"status":"ok","timestamp":1642236485637,"user_tz":-480,"elapsed":12087,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"db61c023-3f7b-491f-ff45-ffad2351e7ab"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["I don't NEG_like NEG_that NEG_place , you keep calling awesome.\n","[\"another restaurant kevin and i frequent when we are out and about in chandler. good prices, and the food is consistently good. i love the vegetarian pizza. in fact, their pizzas are all pretty good. kevin got the nachos last time, which he enjoyed. i am no beer critic, since i pretty much hate it, but since it is a brewery, i can only assume the beer is up to par. the service is also good, and i love how lively it always is, even at ten on a monday night. i always walk away satisfied and with the confidence that i have not NEG_just NEG_wasted NEG_my NEG_money NEG_on NEG_mediocre NEG_food NEG_and NEG_drinks. thanks for being a friend, bj's!\", 1]\n"]},{"output_type":"execute_result","data":{"text/plain":["(3797, 610107)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#Re-train NB model\n","clf_NB = MultinomialNB().fit(train_nega_vectors, Y_nega_train)\n","predNB = clf_NB.predict(test_nega_vectors)\n","pred = list(predNB)\n","\n","print(metrics.confusion_matrix(Y_nega_test, pred))\n","print(np.mean(pred == Y_nega_test) )\n","print(metrics.classification_report(Y_nega_test, pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6k8xwvkI7Ec6","executionInfo":{"status":"ok","timestamp":1642236498710,"user_tz":-480,"elapsed":379,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"5c419025-14a8-44bc-cc03-c21744f5450a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1755   42]\n"," [1128  872]]\n","0.0\n","              precision    recall  f1-score   support\n","\n","          -1       0.61      0.98      0.75      1797\n","           1       0.95      0.44      0.60      2000\n","\n","    accuracy                           0.69      3797\n","   macro avg       0.78      0.71      0.67      3797\n","weighted avg       0.79      0.69      0.67      3797\n","\n"]}]},{"cell_type":"code","source":["#Re-train KNN\n","kn = train_knn(train_nega_vectors, Y_nega_train, 20, 'distance')# distance weights - by inverse of distance\n","predKN = kn.predict(test_nega_vectors)\n","pred = list(predKN)\n","print(metrics.confusion_matrix(Y_nega_test, pred))\n","print(metrics.classification_report(Y_nega_test, pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEXpTVpR7Fto","executionInfo":{"status":"ok","timestamp":1642236512901,"user_tz":-480,"elapsed":6053,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"354628fb-ec14-4463-a20c-04de7d877265"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1474  323]\n"," [ 489 1511]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.75      0.82      0.78      1797\n","           1       0.82      0.76      0.79      2000\n","\n","    accuracy                           0.79      3797\n","   macro avg       0.79      0.79      0.79      3797\n","weighted avg       0.79      0.79      0.79      3797\n","\n"]}]},{"cell_type":"code","source":["#Re-train the SVM\n","model_svm = LinearSVC(C=1.0)\n","clr_svm = model_svm.fit(train_nega_vectors, Y_nega_train)    \n","predicted_nega = clr_svm.predict(test_nega_vectors)\n"," \n","print(metrics.confusion_matrix(Y_nega_test, predicted_nega))\n","print(np.mean(predicted_nega == Y_nega_test) )\n","print(metrics.classification_report(Y_nega_test, predicted_nega))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDUMu16p7H9-","executionInfo":{"status":"ok","timestamp":1642236518067,"user_tz":-480,"elapsed":836,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"bc702b7b-9b2b-4a16-99de-2f81ce2b100a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1516  281]\n"," [ 247 1753]]\n","0.8609428496181196\n","              precision    recall  f1-score   support\n","\n","          -1       0.86      0.84      0.85      1797\n","           1       0.86      0.88      0.87      2000\n","\n","    accuracy                           0.86      3797\n","   macro avg       0.86      0.86      0.86      3797\n","weighted avg       0.86      0.86      0.86      3797\n","\n"]}]},{"cell_type":"code","source":["##Select K Best features\n","\n","ch21 = SelectKBest(chi2, k=600)\n","# Transform your training and testing datasets accordingly\n","train_Kbest = ch21.fit_transform(train_nega_vectors, Y_nega_train)\n","test_Kbest = ch21.transform(test_nega_vectors)\n","train_Kbest.shape\n","\n","model_svm = LinearSVC(C=1.0)\n","# Train your SVM with the k best selected features\n","sv = model_svm.fit(train_Kbest, Y_nega_train)\n","predSVM= sv.predict(test_Kbest)\n","pred = list(predSVM)\n","\n","print(metrics.confusion_matrix(Y_nega_test, pred))\n","print(np.mean(predSVM == Y_nega_test) )\n","print(metrics.classification_report(Y_nega_test, pred))\n","\n","selected_features = list(np.array(vectorizer.get_feature_names())[ch21.get_support()])\n","print (selected_features)\n","\n","#Re-Train ME model\n","clf_ME = LogisticRegression(random_state=0, solver='lbfgs').fit(train_Kbest, Y_nega_train)\n","predME = clf_ME.predict(test_Kbest)\n","pred = list(predME)\n","print(metrics.confusion_matrix(Y_test, pred))\n","print(metrics.classification_report(Y_test, pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSIgLdQ17McB","executionInfo":{"status":"ok","timestamp":1642236533687,"user_tz":-480,"elapsed":2110,"user":{"displayName":"刘景","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07837824912143188451"}},"outputId":"1c428584-093d-4ce1-ca90-57f72b49ec7f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1566  231]\n"," [ 333 1667]]\n","0.8514616802739005\n","              precision    recall  f1-score   support\n","\n","          -1       0.82      0.87      0.85      1797\n","           1       0.88      0.83      0.86      2000\n","\n","    accuracy                           0.85      3797\n","   macro avg       0.85      0.85      0.85      3797\n","weighted avg       0.85      0.85      0.85      3797\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["['10 minutes', '15', '20', '20 minutes', 'absolutely delicious', 'affordable', 'after', 'also have', 'always', 'always good', 'amazing', 'amazing and', 'amazing food', 'amazing the', 'and delicious', 'and friendly', 'and good', 'and great', 'and left', 'and said', 'another', 'are always', 'are great', 'arugula', 'as good', 'as well', 'asked', 'asked for', 'asked if', 'at all', 'at best', 'atmosphere', 'attentive', 'authentic', 'average', 'awesome', 'awesome and', 'awful', 'back again', 'bad', 'bad service', 'bagel', 'bagels', 'bar bianco', 'bar next', 'barely', 'bass', 'be back', 'because', 'belly', 'best', 'best have', 'best in', 'best pizza', 'best thai', 'best ve', 'better', 'bianco', 'biancoverde', 'bill', 'bland', 'bland and', 'brazilian', 'bun', 'burger', 'burger was', 'burgers', 'burnt', 'but worth', 'cab', 'came', 'can neg_wait', 'card', 'catfish', 'champagne', 'charge', 'charged', 'chris', 'closed', 'coconut', 'coconut ice', 'cold', 'cold and', 'crispy', 'crispy duck', 'crispy rice', 'crust', 'curry', 'dancer', 'dancers', 'date', 'decent', 'definitely', 'definitely be', 'definitely come', 'definitely go', 'definitely recommend', 'definitely worth', 'delicious', 'delicious and', 'delicious the', 'did', 'did not', 'didn', 'didn neg_even', 'die', 'die for', 'dirty', 'disappointed', 'disappointing', 'disappointment', 'disgusting', 'dishes', 'don neg_let', 'drunken', 'drunken noodle', 'drunken noodles', 'dry', 'dry and', 'duck', 'duck curry', 'duck with', 'elsewhere', 'empty', 'enjoy', 'enjoyed', 'eno', 'even better', 'ever', 'ever had', 'every', 'everything', 'excellent', 'excellent food', 'excellent service', 'extensive', 'fabulous', 'family owned', 'fantastic', 'favorite', 'favorite is', 'favorites', 'flavorful', 'flavorless', 'food great', 'food poisoning', 'food ve', 'food was', 'forever', 'fresh', 'fresh and', 'friendly', 'friendly and', 'friendly staff', 'fries', 'fries were', 'frozen', 'garlic', 'garlic prawns', 'gem', 'get our', 'good', 'good as', 'good but', 'good food', 'good too', 'greasy', 'great', 'great and', 'great atmosphere', 'great food', 'great pizza', 'great place', 'great prices', 'great service', 'great thai', 'great time', 'great too', 'great value', 'great wine', 'green curry', 'gross', 'guess', 'had no', 'had to', 'hands', 'hands down', 'have ever', 'have great', 'he', 'her', 'hidden', 'hidden gem', 'highly', 'highly recommend', 'him', 'homemade', 'horrible', 'horrible service', 'hostess', 'ignored', 'in madison', 'in phoenix', 'in town', 'in vegas', 'incredible', 'instead', 'is', 'is always', 'is amazing', 'is awesome', 'is delicious', 'is excellent', 'is fantastic', 'is friendly', 'is great', 'is horrible', 'is must', 'is my', 'is one', 'is terrible', 'is the', 'it took', 'it wasn', 'just', 'just ok', 'kai', 'kao', 'kao tod', 'kitchen', 'lacked', 'lacking', 'las', 'las vegas', 'left', 'list', 'looked', 'lotus', 'lotus of', 'love', 'love it', 'love love', 'love the', 'love their', 'love this', 'loved', 'loved it', 'lox', 'lox stock', 'madison', 'make reservations', 'mall', 'management', 'manager', 'mango', 'margherita', 'maybe', 'me', 'meat', 'meat was', 'mediocre', 'meh', 'metro', 'metro pizza', 'minutes', 'minutes later', 'minutes to', 'money', 'money and', 'mozzarella', 'must', 'must try', 'my favorite', 'my favorites', 'my food', 'nam', 'nam kao', 'nasty', 'neg_again', 'neg_all', 'neg_and', 'neg_at neg_all', 'neg_back', 'neg_back neg_here', 'neg_back neg_to', 'neg_be', 'neg_be neg_back', 'neg_be neg_coming', 'neg_be neg_disappointed', 'neg_be neg_going', 'neg_be neg_returning', 'neg_beat', 'neg_care', 'neg_come', 'neg_come neg_back', 'neg_coming', 'neg_coming neg_back', 'neg_disappoint', 'neg_disappointed', 'neg_even', 'neg_for', 'neg_fresh', 'neg_go', 'neg_go neg_back', 'neg_go neg_wrong', 'neg_going', 'neg_going neg_back', 'neg_good', 'neg_great', 'neg_here', 'neg_here neg_again', 'neg_impressed', 'neg_it', 'neg_let neg_the', 'neg_money', 'neg_my', 'neg_our', 'neg_recommend', 'neg_recommend neg_this', 'neg_return', 'neg_returning', 'neg_special', 'neg_taste', 'neg_thai', 'neg_that', 'neg_that neg_great', 'neg_the', 'neg_they', 'neg_this', 'neg_time', 'neg_to', 'neg_to neg_this', 'neg_us', 'neg_wait', 'neg_wait neg_to', 'neg_was', 'neg_waste', 'neg_waste neg_your', 'neg_we', 'neg_were', 'neg_what', 'neg_worth', 'neg_worth neg_it', 'neg_worth neg_the', 'never', 'never neg_again', 'never neg_go', 'next door', 'no', 'no flavor', 'no one', 'northern', 'northern thai', 'not', 'not neg_come', 'not neg_disappoint', 'not neg_disappointed', 'not neg_even', 'not neg_go', 'not neg_good', 'not neg_great', 'not neg_impressed', 'not neg_recommend', 'not neg_worth', 'notch', 'nothing', 'nothing neg_special', 'of siam', 'ok', 'ok but', 'okay', 'one of', 'ordered', 'our', 'our food', 'our order', 'outstanding', 'oven', 'over', 'over cooked', 'over priced', 'overcooked', 'overpriced', 'pad', 'pad thai', 'paid', 'panang', 'panang curry', 'paying', 'perfect', 'perfection', 'perfectly', 'phoenix', 'pie', 'pizza', 'pizza have', 'pizza in', 'pizza is', 'pizzas', 'pizzeria', 'pizzeria bianco', 'place to', 'poisoning', 'poor', 'poor service', 'prawn', 'prawns', 'pricey but', 'ramen', 'rather', 'really good', 'reasonable', 'reasonable prices', 'recommend', 'recommend it', 'recommend the', 'recommend this', 'recommended', 'reservations', 'restaurant in', 'rosa', 'rude', 'rude and', 'said', 'salty', 'save your', 'sea', 'sea bass', 'seemed', 'server', 'service great', 'she', 'she said', 'should', 'should have', 'siam', 'siam is', 'sichuan', 'sick', 'slow', 'so delicious', 'so good', 'soggy', 'someone', 'somewhere else', 'sonny', 'sonny boy', 'sorry', 'spice', 'spicy', 'spot', 'staff is', 'stale', 'sticky rice', 'strip', 'strip mall', 'stuffed', 'sub par', 'sucks', 'super friendly', 'sure to', 'table', 'take our', 'tasted', 'tasted like', 'tasteless', 'tasty', 'terrible', 'terrible service', 'thai', 'thai food', 'thai restaurant', 'thai restaurants', 'thailand', 'that', 'the belly', 'the best', 'the biancoverde', 'the burger', 'the check', 'the crispy', 'the drunken', 'the fries', 'the garlic', 'the manager', 'the margherita', 'the meat', 'the perfect', 'the rosa', 'the server', 'the strip', 'the table', 'the tom', 'the valley', 'the wait', 'the waitress', 'the worst', 'then', 'there was', 'thin crust', 'this is', 'to', 'to be', 'to die', 'to lotus', 'to vegas', 'tod', 'told', 'tom', 'tom yum', 'took', 'took forever', 'top notch', 'totally worth', 'tott', 'tough', 'town', 'tried to', 'trip', 'try the', 'two stars', 'unfortunately', 'us', 'valley', 've', 've ever', 'vegas', 'very disappointed', 'very disappointing', 'very friendly', 'very good', 'very reasonable', 'vino', 'wait', 'wait but', 'waited', 'waiter', 'waitress', 'walked', 'wanted', 'was', 'was amazing', 'was awesome', 'was awful', 'was bland', 'was cold', 'was decent', 'was delicious', 'was dry', 'was excellent', 'was fantastic', 'was great', 'was horrible', 'was just', 'was mediocre', 'was not', 'was ok', 'was okay', 'was perfect', 'was terrible', 'wasn', 'waste', 'waste of', 'water', 'way too', 'we', 'we asked', 'we were', 'we won', 'well worth', 'were', 'were not', 'whenever', 'will definitely', 'will never', 'will not', 'wine', 'wine list', 'wise guy', 'wiseguy', 'won', 'won neg_be', 'wonderful', 'world', 'worse', 'worst', 'worst service', 'worth', 'worth it', 'worth the', 'would', 'would definitely', 'would not', 'would recommend', 'wouldn', 'wrong', 'you', 'you will', 'yum', 'yummy']\n","[[1598  199]\n"," [ 478 1522]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.77      0.89      0.83      1797\n","           1       0.88      0.76      0.82      2000\n","\n","    accuracy                           0.82      3797\n","   macro avg       0.83      0.83      0.82      3797\n","weighted avg       0.83      0.82      0.82      3797\n","\n"]}]}]}